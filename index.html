<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Geometrically-Constrained Agent (GCA): A training-free agentic paradigm that resolves the semantic-to-geometric gap in Spatial Reasoning.">
  <meta name="keywords" content="Spatial Reasoning, VLM, Agent, Geometric Constraint, Robotics, Computer Vision">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Geometrically-Constrained Agent for Spatial Reasoning</title>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">

  <link rel="stylesheet" href="./static/source_serif_4.css">
  <link rel="stylesheet" href="./static/source_sans_3.css">  
  <link rel="stylesheet" href="./static/academicons.min.css">
  <link rel="stylesheet" href="./static/fontawesome/css/fontawesome.css">
  <link rel="stylesheet" href="./static/fontawesome/css/brands.css">
  <link rel="stylesheet" href="./static/fontawesome/css/light.css">


  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <!-- <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="#">
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
      </a>

      <div class="navbar-item has-dropdown is-hoverable">
        <a class="navbar-link">
          More Research
        </a>
        <div class="navbar-dropdown">
          <a class="navbar-item" href="https://ursulalujun.github.io/isbench.github.io/">
            IS-Bench
          </a>
        </div>
      </div>
    </div>

  </div> -->
</nav>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-3 publication-title">Geometrically-Constrained Agent for Spatial Reasoning</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://github.com/Zx55">Zeren Chen</a><sup>1,2*</sup>,</span>
            <span class="author-block">
              <a href="https://github.com/ursulalujun">Xiaoya Lu</a><sup>2,3*</sup>,</span>
            <span class="author-block">
              <a href="#">Zhijie Zheng</a><sup>1,2</sup>,
            </span>
            <span class="author-block">
              <a href="#">Pengrui Li</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a href="#">Lehan He</a><sup>1,4</sup>,
            </span>
            <span class="author-block">
              <a href="#">Yijin Zhou</a><sup>2,3,4</sup>,
            </span>
            <br>
            <span class="author-block">
              <a href="https://amandajshao.github.io">Jing Shao</a><sup>2</sup>,
            </span>
            <span class="author-block">
              <a href="#">Bohan Zhuang</a><sup>5†</sup>,
            </span>
            <span class="author-block">
              <a href="#">Lu Sheng</a><sup>1†</sup>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>School of Software, Beihang University,</span>
            <span class="author-block"><sup>2</sup>Shanghai AI Laboratory,</span>
            <span class="author-block"><sup>3</sup>Shanghai Jiao Tong University,</span><br>
            <span class="author-block"><sup>4</sup>Shanghai Innovation Institute,</span>
            <span class="author-block"><sup>5</sup>ZIP Lab, Zhejiang University</span>
          </div>

          <div class="is-size-6 publication-authors">
            <span class="author-block">*Equal Contribution, †Corresponding Author</span>
          </div>

          <div class="button-container">
            <a href="https://arxiv.org/abs/2511.22659" target="_blank" class="button"><i class="ai ai-arxiv"></i>&emsp14;arXiv</a>
            <a href="https://github.com/gca-spatial-reasoning/gca" target="_blank" class="button"><i class="fa-light fa-code"></i>&emsp14;Code</a>
          </div> 
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <img src="./static/images/teaser_page.jpg" alt="Semantic-Geometric Gap vs Geometrically-Constrained Spatial Reasoning" style="width:100%; height:auto;">
      <h2 class="subtitle has-text-centered">
        <strong>Geometrically-Constrained Agent (GCA)</strong> resolves the semantic-to-geometric gap by decoupling the reasoning process into 
        Task Formalization and Constrained Geometric Computation.
      </h2>
    </div>
  </div>
</section>
  
<section class="hero is-light is-small">
  <div class="hero-body">
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item item-steve">
          <video poster="" id="steve" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/case_1.mp4" type="video/mp4">
          </video>
          <h2 class="subtitle has-text-centered">
            Case Study #1: Unique Object Counting across Multiple Views
          </h2>
        </div>
        <div class="item item-chair-tp">
          <video poster="" id="chair-tp" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/case_2.mp4" type="video/mp4">
          </video>
          <h2 class="subtitle has-text-centered">
            Case Study #2: Spatial Relationship Reasoning under Direction-Based Reference Frame
          </h2>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Vision Language Models (VLMs) exhibit a fundamental <strong>semantic-to-geometric gap</strong> in spatial reasoning: they excel
            at qualitative semantic inference but their reasoning operates within a lossy semantic space, misaligned with high-fidelity geometry.
            Current paradigms fail to bridge this gap. Training-based methods suffer from an "oracle paradox,"
            learning flawed spatial logic from imperfect oracles. Tool-integrated methods constrain the final computation but critically 
            leave the VLM's planning process unconstrained, resulting in geometrically flawed plans.
            In this work, we propose <strong>Geometrically-Constrained Agent (GCA)</strong>, a training-free agentic paradigm that resolves this gap by introducing
            a formal task constraint. Specifically, we strategically decouple the VLM's role into two stages:
            1) Acting as a semantic analyst, the VLM translates the user's ambiguous query into a formal, verifiable task constraint, which defines the reference frame and objective.
            2) Acting as a task solver, the VLM generates and executes tool calls strictly within the deterministic bounds defined by the constraint.
            This geometrically-constrained reasoning strategy successfully resolves the semantic-to-geometric gap, yielding a robust and verifiable reasoning pathway. 
            Comprehensive experiments demonstrate that GCA achieves SOTA performance on multiple spatial reasoning benchmarks, surpassing existing methods by <strong>~27%</strong>.
          </p>
        </div>
      </div>
    </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Overview of GCA</h2>
        <div class="content has-text-justified">
          <img src="./static/images/overall_paradigm_page.jpg" alt="Overall Paradigm of GCA" style="width:100%; height:auto;">
          <p>
           We introduce Geometrically-Constrained Agent (GCA), a training-free agentic paradigm for geometrically-constrained spatial reasoning.
           This strategy leverages a formal task constraint, C<sub>task</sub>, to decouple the reasoning process into two stages:
          </p>
          <p>
            1. <strong>Task Formalization.</strong> The VLM, acting as a semantic analyst, translates the ambiguous query and visual data into the formal, verifiable task constraint C<sub>task</sub>. This stage defines what to solve, establishing immutable sub-constraints: a reference frame constraint and an objective constraint. <br>
            2. <strong>Constrained Geometric Computation.</strong> The VLM then, acting as a task solver, generates and executes tool calls to compute the final answer, operating strictly within the deterministic bounds defined by C<sub>task</sub>.
          </p>
          <img src="./static/images/ref_frame_page.jpg" alt="Overall Paradigm of GCA" style="display: block; margin: 0 auto; width: 75%; height: auto;">
          <p>
            Formal Task Constraint C<sub>task</sub> bridges the semantic-to-geometric gap, which contains two key sub-constraints: <br>
            1. <strong>Reference Frame Constraint</strong> that defines the coordinate system for answering the query. <br>
            2. <strong>Objective Constraint</strong> that specifies the objective to be measured within that frame.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
  
<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Performance of GCA</h2>
        <div class="content has-text-justified">
          <p>
            <strong>Performance across VLMs</strong> GCA proves to be a robust architectural solution, achieving an average of <strong>37%</strong> relative improvement across all tested models. 
            Notably, the magnitude of enhancement correlates with the base VLM's agentic proficiency, unlocking up to <strong>49%</strong> gain on stronger models like Gemini-2.5-Pro. <br>
            <strong>Impact of Task Constraint</strong> Simply prompting the VLM or using unconstrained tools ("Tool (Prompt)") yields negligible improvements. 
            In contrast, our GCA delivers a substantial performance boost.
          </p>
    
          <div class="columns is-centered">
            <div class="column">
              <img src="./static/images/generalizability_ablation_page.jpg" alt="Right Image Description" style="width:100%; height:auto;">
            </div>
            <div class="column">
              <img src="./static/images/formalize_ablation_page.jpg" alt="Left Image Description" style="width:90%; height:auto;">
            </div>
          </div>
          <p>
            <strong>Error Attribution and Failure Modes</strong> A key advantage of GCA is its interpretable reasoning pathway. We conduct a detailed error attribution analysis to identify bottlenecks. 
            Results indicate that <strong>30%</strong> of errors stem from the initial Task Formalization stage, while the remaining <strong>70%</strong> occur during the Geometric Computation stage.
          </p>
          <img src="./static/images/failure_case_page.jpg" alt="Overall Paradigm of GCA" style="width:100%; height:auto;">
          
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>
      @misc{chen2025geometricallyconstrainedagentspatialreasoning,
      title={Geometrically-Constrained Agent for Spatial Reasoning}, 
      author={Zeren Chen and Xiaoya Lu and Zhijie Zheng and Pengrui Li and Lehan He and Yijin Zhou and Jing Shao and Bohan Zhuang and Lu Sheng},
      year={2025},
      eprint={2511.22659},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2511.22659}, 
}
</code></pre>
  </div>
</section>

  

<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link"
         href="#">
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link" href="#" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            Template borrowed from <a
              href="https://github.com/nerfies/nerfies.github.io">Nerfies</a>.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
